{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "run_logdir = get_run_logdir()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-07 16:01:51.272100: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-03-07 16:01:51.272215: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-07 16:01:51.272748: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-07 16:01:51.291354: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2022-03-07 16:01:51.291371: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2022-03-07 16:01:51.291392: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
      "2022-03-07 16:01:51.310502: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-03-07 16:01:51.336116: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3686400000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 77/363 [=====>........................] - ETA: 0s - loss: 5.6346"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-07 16:01:51.604119: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.\n",
      "2022-03-07 16:01:51.604141: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.\n",
      "2022-03-07 16:01:51.611195: I tensorflow/core/profiler/lib/profiler_session.cc:71] Profiler session collecting data.\n",
      "2022-03-07 16:01:51.611718: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.\n",
      "2022-03-07 16:01:51.612668: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: ./my_logs/run_2022_03_07-16_01_49/train/plugins/profile/2022_03_07_16_01_51\n",
      "2022-03-07 16:01:51.613127: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to ./my_logs/run_2022_03_07-16_01_49/train/plugins/profile/2022_03_07_16_01_51/asgrim-arch-desktop.trace.json.gz\n",
      "2022-03-07 16:01:51.614336: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: ./my_logs/run_2022_03_07-16_01_49/train/plugins/profile/2022_03_07_16_01_51\n",
      "2022-03-07 16:01:51.614394: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to ./my_logs/run_2022_03_07-16_01_49/train/plugins/profile/2022_03_07_16_01_51/asgrim-arch-desktop.memory_profile.json.gz\n",
      "2022-03-07 16:01:51.614490: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: ./my_logs/run_2022_03_07-16_01_49/train/plugins/profile/2022_03_07_16_01_51Dumped tool data for xplane.pb to ./my_logs/run_2022_03_07-16_01_49/train/plugins/profile/2022_03_07_16_01_51/asgrim-arch-desktop.xplane.pb\n",
      "Dumped tool data for overview_page.pb to ./my_logs/run_2022_03_07-16_01_49/train/plugins/profile/2022_03_07_16_01_51/asgrim-arch-desktop.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to ./my_logs/run_2022_03_07-16_01_49/train/plugins/profile/2022_03_07_16_01_51/asgrim-arch-desktop.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to ./my_logs/run_2022_03_07-16_01_49/train/plugins/profile/2022_03_07_16_01_51/asgrim-arch-desktop.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to ./my_logs/run_2022_03_07-16_01_49/train/plugins/profile/2022_03_07_16_01_51/asgrim-arch-desktop.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 1s 3ms/step - loss: 3.3288 - val_loss: 0.7796\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.7660 - val_loss: 0.6453\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.6220 - val_loss: 0.6001\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5769 - val_loss: 0.5717\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5414 - val_loss: 0.5476\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5346 - val_loss: 0.5303\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5126 - val_loss: 0.5157\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4916 - val_loss: 0.5045\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4959 - val_loss: 0.4955\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4825 - val_loss: 0.4883\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4813 - val_loss: 0.4830\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4529 - val_loss: 0.4779\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4456 - val_loss: 0.4732\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4768 - val_loss: 0.4700\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4551 - val_loss: 0.4683\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4601 - val_loss: 0.4639\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 856us/step - loss: 0.4328 - val_loss: 0.4632\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 967us/step - loss: 0.4666 - val_loss: 0.4593\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4422 - val_loss: 0.4570\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4346 - val_loss: 0.4561\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4444 - val_loss: 0.4541\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4448 - val_loss: 0.4515\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4495 - val_loss: 0.4498\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4215 - val_loss: 0.4470\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 959us/step - loss: 0.4226 - val_loss: 0.4475\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4184 - val_loss: 0.4463\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4247 - val_loss: 0.4435\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4279 - val_loss: 0.4415\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4135 - val_loss: 0.4417\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4236 - val_loss: 0.4397\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Fine tuning Neural Networks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "X_new = X_test[:3]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]) -> keras.models.Sequential:\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.6195 - val_loss: 0.7676\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.8228 - val_loss: 0.6127\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5930 - val_loss: 0.5436\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.5167 - val_loss: 0.5164\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4790 - val_loss: 0.4981\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4823 - val_loss: 0.4882\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4658 - val_loss: 0.4783\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 960us/step - loss: 0.4570 - val_loss: 0.4724\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 857us/step - loss: 0.4594 - val_loss: 0.4673\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4494 - val_loss: 0.4630\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4549 - val_loss: 0.4597\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4300 - val_loss: 0.4560\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4247 - val_loss: 0.4529\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4541 - val_loss: 0.4505\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4351 - val_loss: 0.4510\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4389 - val_loss: 0.4456\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4128 - val_loss: 0.4473\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4453 - val_loss: 0.4418\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4238 - val_loss: 0.4411\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4151 - val_loss: 0.4401\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4255 - val_loss: 0.4370\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4238 - val_loss: 0.4357\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4275 - val_loss: 0.4323\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4028 - val_loss: 0.4305\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4043 - val_loss: 0.4330\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3964 - val_loss: 0.4328\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4035 - val_loss: 0.4283\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4105 - val_loss: 0.4257\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3929 - val_loss: 0.4257\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4007 - val_loss: 0.4228\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 826us/step - loss: 0.4076 - val_loss: 0.4255\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4105 - val_loss: 0.4240\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3926 - val_loss: 0.4246\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4162 - val_loss: 0.4214\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3766 - val_loss: 0.4184\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3902 - val_loss: 0.4168\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3862 - val_loss: 0.4176\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3797 - val_loss: 0.4150\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4016 - val_loss: 0.4158\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3801 - val_loss: 0.4159\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3900 - val_loss: 0.4110\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3704 - val_loss: 0.4133\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3801 - val_loss: 0.4093\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3802 - val_loss: 0.4074\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3809 - val_loss: 0.4082\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3689 - val_loss: 0.4059\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3721 - val_loss: 0.4072\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3640 - val_loss: 0.4068\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3677 - val_loss: 0.4040\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3746 - val_loss: 0.4052\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3991 - val_loss: 0.4044\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3730 - val_loss: 0.4040\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3794 - val_loss: 0.3996\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3639 - val_loss: 0.3995\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3556 - val_loss: 0.4026\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3731 - val_loss: 0.3985\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 860us/step - loss: 0.3597 - val_loss: 0.3969\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3648 - val_loss: 0.3963\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3576 - val_loss: 0.3967\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 988us/step - loss: 0.3598 - val_loss: 0.3970\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3685 - val_loss: 0.3961\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3547 - val_loss: 0.3965\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3723 - val_loss: 0.3935\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3456 - val_loss: 0.3957\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3578 - val_loss: 0.3944\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3685 - val_loss: 0.3931\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3502 - val_loss: 0.3929\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 963us/step - loss: 0.3510 - val_loss: 0.3963\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3519 - val_loss: 0.3964\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 971us/step - loss: 0.3622 - val_loss: 0.3976\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 916us/step - loss: 0.3613 - val_loss: 0.3914\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 956us/step - loss: 0.3454 - val_loss: 0.3908\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 930us/step - loss: 0.3760 - val_loss: 0.3895\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3466 - val_loss: 0.3892\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3614 - val_loss: 0.3879\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 976us/step - loss: 0.3544 - val_loss: 0.3877\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 982us/step - loss: 0.3432 - val_loss: 0.3906\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3570 - val_loss: 0.3880\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 0s 865us/step - loss: 0.3405 - val_loss: 0.3885\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 0s 665us/step - loss: 0.3483 - val_loss: 0.3861\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 0s 721us/step - loss: 0.3527 - val_loss: 0.3864\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3491 - val_loss: 0.3913\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 0s 692us/step - loss: 0.3480 - val_loss: 0.3876\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 0s 694us/step - loss: 0.3442 - val_loss: 0.3862\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 0s 690us/step - loss: 0.3439 - val_loss: 0.3926\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 0s 725us/step - loss: 0.3423 - val_loss: 0.3863\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 0s 693us/step - loss: 0.3521 - val_loss: 0.3851\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 0s 819us/step - loss: 0.3399 - val_loss: 0.3836\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 0s 722us/step - loss: 0.3556 - val_loss: 0.3833\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 0s 834us/step - loss: 0.3542 - val_loss: 0.3850\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 0s 819us/step - loss: 0.3420 - val_loss: 0.3828\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 0s 719us/step - loss: 0.3542 - val_loss: 0.3844\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 0s 797us/step - loss: 0.3427 - val_loss: 0.3833\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 0s 864us/step - loss: 0.3346 - val_loss: 0.3805\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 0s 683us/step - loss: 0.3354 - val_loss: 0.3811\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 0s 759us/step - loss: 0.3373 - val_loss: 0.3871\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 0s 940us/step - loss: 0.3465 - val_loss: 0.3789\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3351 - val_loss: 0.3782\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 0s 724us/step - loss: 0.3279 - val_loss: 0.3783\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 0s 774us/step - loss: 0.3372 - val_loss: 0.3789\n",
      "162/162 [==============================] - 0s 438us/step - loss: 0.3601\n"
     ]
    },
    {
     "data": {
      "text/plain": "-0.3601016700267792"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid),\n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "mse_test = keras_reg.score(X_test, y_test)\n",
    "y_pred = keras_reg.predict(X_new)\n",
    "\n",
    "mse_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mstats\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m reciprocal\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_selection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m RandomizedSearchCV\n\u001B[1;32m      4\u001B[0m param_distribs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mn_hidden\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m3\u001B[39m],\n\u001B[0;32m----> 6\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mn_neurons\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[43mnp\u001B[49m\u001B[38;5;241m.\u001B[39marange(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m100\u001B[39m),\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlearning_rate\u001B[39m\u001B[38;5;124m\"\u001B[39m: reciprocal(\u001B[38;5;241m3e-4\u001B[39m, \u001B[38;5;241m3e-2\u001B[39m)\n\u001B[1;32m      8\u001B[0m }\n\u001B[1;32m     10\u001B[0m rnd_search_cv \u001B[38;5;241m=\u001B[39m RandomizedSearchCV(keras_reg, param_distribs, n_iter\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m)\n\u001B[1;32m     11\u001B[0m rnd_search_cv\u001B[38;5;241m.\u001B[39mfit(X_train, y_train, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, validation_data\u001B[38;5;241m=\u001B[39m(X_valid, y_valid),\n\u001B[1;32m     12\u001B[0m                   callbacks\u001B[38;5;241m=\u001B[39m[keras\u001B[38;5;241m.\u001B[39mcallbacks\u001B[38;5;241m.\u001B[39mEarlyStopping(patience\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m)])\n",
      "\u001B[0;31mNameError\u001B[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2)\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "{'learning_rate': 0.003601683277857631, 'n_hidden': 3, 'n_neurons': 26}"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "-0.31665848692258197"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "learning_rate, n_hidden, n_neurons = rnd_search_cv.best_params_.values()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "model = build_model(n_hidden, n_neurons, learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "model.save(\"best_reg_model.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 1.8119 - val_loss: 0.7216\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7417 - val_loss: 0.6086\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5830 - val_loss: 0.5496\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5255 - val_loss: 0.5188\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4854 - val_loss: 0.4962\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4819 - val_loss: 0.4812\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4615 - val_loss: 0.4668\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4468 - val_loss: 0.4592\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4427 - val_loss: 0.4499\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.4345 - val_loss: 0.4458\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4329 - val_loss: 0.4394\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4104 - val_loss: 0.4342\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4015 - val_loss: 0.4307\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4271 - val_loss: 0.4272\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4011 - val_loss: 0.4334\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4040 - val_loss: 0.4173\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3800 - val_loss: 0.4162\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.4074 - val_loss: 0.4095\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3854 - val_loss: 0.4072\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3778 - val_loss: 0.4043\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3887 - val_loss: 0.4023\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3837 - val_loss: 0.4019\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3821 - val_loss: 0.3969\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3658 - val_loss: 0.3945\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3604 - val_loss: 0.3941\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3587 - val_loss: 0.3943\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3571 - val_loss: 0.4008\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4010 - val_loss: 0.3968\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3459 - val_loss: 0.3885\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3561 - val_loss: 0.3892\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3631 - val_loss: 0.3860\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3611 - val_loss: 0.3797\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3453 - val_loss: 0.3761\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3643 - val_loss: 0.3744\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3261 - val_loss: 0.3769\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3403 - val_loss: 0.3758\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3337 - val_loss: 0.3776\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3289 - val_loss: 0.3700\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3452 - val_loss: 0.3746\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3250 - val_loss: 0.3668\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3373 - val_loss: 0.3671\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3190 - val_loss: 0.3661\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3241 - val_loss: 0.3719\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3288 - val_loss: 0.3620\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3263 - val_loss: 0.3656\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3156 - val_loss: 0.3666\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3227 - val_loss: 0.3610\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3098 - val_loss: 0.3653\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3176 - val_loss: 0.3701\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3291 - val_loss: 0.3572\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3383 - val_loss: 0.3506\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3163 - val_loss: 0.3577\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3212 - val_loss: 0.3475\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3088 - val_loss: 0.3493\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3043 - val_loss: 0.3512\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3146 - val_loss: 0.3473\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2993 - val_loss: 0.3474\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3114 - val_loss: 0.3418\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2982 - val_loss: 0.3402\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2983 - val_loss: 0.3403\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3158 - val_loss: 0.3416\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2993 - val_loss: 0.3472\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3141 - val_loss: 0.3446\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2885 - val_loss: 0.3389\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2999 - val_loss: 0.3415\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3035 - val_loss: 0.3349\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2890 - val_loss: 0.3364\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2901 - val_loss: 0.3403\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2897 - val_loss: 0.3494\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3023 - val_loss: 0.3447\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2968 - val_loss: 0.3347\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2846 - val_loss: 0.3323\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3137 - val_loss: 0.3315\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2864 - val_loss: 0.3330\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2996 - val_loss: 0.3363\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.2902 - val_loss: 0.3273\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2797 - val_loss: 0.3283\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2968 - val_loss: 0.3284\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2815 - val_loss: 0.3279\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 0s 901us/step - loss: 0.2842 - val_loss: 0.3269\n",
      "Epoch 81/100\n",
      "363/363 [==============================] - 0s 967us/step - loss: 0.2876 - val_loss: 0.3276\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 0s 941us/step - loss: 0.2843 - val_loss: 0.3278\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2791 - val_loss: 0.3353\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 0s 921us/step - loss: 0.2860 - val_loss: 0.3305\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 0s 986us/step - loss: 0.2835 - val_loss: 0.3332\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2780 - val_loss: 0.3286\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2843 - val_loss: 0.3264\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 0s 915us/step - loss: 0.2776 - val_loss: 0.3287\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 0s 968us/step - loss: 0.2912 - val_loss: 0.3254\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2885 - val_loss: 0.3272\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 0s 979us/step - loss: 0.2827 - val_loss: 0.3256\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2935 - val_loss: 0.3215\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 0s 835us/step - loss: 0.2791 - val_loss: 0.3255\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 0s 882us/step - loss: 0.2718 - val_loss: 0.3193\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 0s 982us/step - loss: 0.2760 - val_loss: 0.3223\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2767 - val_loss: 0.3207\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2829 - val_loss: 0.3181\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2782 - val_loss: 0.3170\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2702 - val_loss: 0.3176\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2754 - val_loss: 0.3195\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7ff65c248610>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid),\n",
    "          callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 422us/step - loss: 0.3007\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.3007470369338989"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}