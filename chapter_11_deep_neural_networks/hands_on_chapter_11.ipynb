{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import keras.losses\n",
    "from keras.layers import Flatten, Dense, BatchNormalization\n",
    "from keras.models import Sequential"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-16 17:47:18.308025: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-16 17:47:18.372677: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-16 17:47:18.372771: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-16 17:47:18.374292: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-16 17:47:18.374771: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-16 17:47:18.374869: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-16 17:47:18.374918: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-16 17:47:18.862933: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-16 17:47:18.863082: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-16 17:47:18.863156: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-16 17:47:18.863226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5429 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape=[28, 28]),\n",
    "    BatchNormalization(),\n",
    "    Dense(300, activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dense(100, activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dense(10, activation=\"softmax\")\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 784)              3136      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 300)               235500    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 300)              1200      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 100)              400       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "[('batch_normalization/gamma:0', True),\n ('batch_normalization/beta:0', True),\n ('batch_normalization/moving_mean:0', False),\n ('batch_normalization/moving_variance:0', False)]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(var.name, var.trainable) for var in model.layers[1].variables]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Gradient Clipping"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from keras.optimizers import gradient_descent_v2\n",
    "\n",
    "optimizer = gradient_descent_v2.SGD(clipvalue=1.0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "\n",
    "\n",
    "def split_dataset(X, y):\n",
    "    y_5_or_6 = (y == 5) | (y == 6)  # sandals or shirts\n",
    "    y_A = y[~y_5_or_6]\n",
    "    y_A[y_A > 6] -= 2  # class indices 7, 8, 9 should be moved to 5, 6, 7\n",
    "    y_B = (y[y_5_or_6] == 6).astype(np.float32)  # binary classification task: is it a shirt (class 6)?\n",
    "    return ((X[~y_5_or_6], y_A),\n",
    "            (X[y_5_or_6], y_B))\n",
    "\n",
    "\n",
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
    "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
    "X_train_B = X_train_B[:200]\n",
    "y_train_B = y_train_B[:200]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "pixel_means = X_train.mean(axis=0, keepdims=True)\n",
    "pixel_stds = X_train.std(axis=0, keepdims=True)\n",
    "X_train_scaled = (X_train - pixel_means) / pixel_stds\n",
    "X_valid_scaled = (X_valid - pixel_means) / pixel_stds\n",
    "X_test_scaled = (X_test - pixel_means) / pixel_stds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "(43986, 28, 28)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_A.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "(200, 28, 28)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_B.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "model_A = Sequential()\n",
    "model_A.add(Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_A.add(Dense(n_hidden, activation=\"selu\"))\n",
    "model_A.add(Dense(8, activation=\"softmax\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=gradient_descent_v2.SGD(learning_rate=1e-3),\n",
    "                metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 152/1375 [==>...........................] - ETA: 1s - loss: 1.2267 - accuracy: 0.6030"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-16 17:47:20.971326: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1375/1375 [==============================] - 3s 1ms/step - loss: 0.5695 - accuracy: 0.8142 - val_loss: 0.3775 - val_accuracy: 0.8787\n",
      "Epoch 2/20\n",
      "1375/1375 [==============================] - 1s 1ms/step - loss: 0.3540 - accuracy: 0.8778 - val_loss: 0.3208 - val_accuracy: 0.8954\n",
      "Epoch 3/20\n",
      "1375/1375 [==============================] - 1s 1ms/step - loss: 0.3156 - accuracy: 0.8895 - val_loss: 0.3110 - val_accuracy: 0.8926\n",
      "Epoch 4/20\n",
      "1375/1375 [==============================] - 1s 1ms/step - loss: 0.2952 - accuracy: 0.8972 - val_loss: 0.2843 - val_accuracy: 0.9026\n",
      "Epoch 5/20\n",
      "1375/1375 [==============================] - 1s 1ms/step - loss: 0.2815 - accuracy: 0.9019 - val_loss: 0.2745 - val_accuracy: 0.9073\n",
      "Epoch 6/20\n",
      "1375/1375 [==============================] - 1s 1ms/step - loss: 0.2708 - accuracy: 0.9060 - val_loss: 0.2695 - val_accuracy: 0.9098\n",
      "Epoch 7/20\n",
      "1375/1375 [==============================] - 1s 1ms/step - loss: 0.2629 - accuracy: 0.9084 - val_loss: 0.2648 - val_accuracy: 0.9096\n",
      "Epoch 8/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2567 - accuracy: 0.9120 - val_loss: 0.2570 - val_accuracy: 0.9153\n",
      "Epoch 9/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2506 - accuracy: 0.9133 - val_loss: 0.2538 - val_accuracy: 0.9145\n",
      "Epoch 10/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2460 - accuracy: 0.9155 - val_loss: 0.2539 - val_accuracy: 0.9155\n",
      "Epoch 11/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2417 - accuracy: 0.9167 - val_loss: 0.2491 - val_accuracy: 0.9188\n",
      "Epoch 12/20\n",
      "1375/1375 [==============================] - 1s 1ms/step - loss: 0.2379 - accuracy: 0.9189 - val_loss: 0.2484 - val_accuracy: 0.9168\n",
      "Epoch 13/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2343 - accuracy: 0.9201 - val_loss: 0.2451 - val_accuracy: 0.9155\n",
      "Epoch 14/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2308 - accuracy: 0.9211 - val_loss: 0.2561 - val_accuracy: 0.9143\n",
      "Epoch 15/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2277 - accuracy: 0.9223 - val_loss: 0.2434 - val_accuracy: 0.9193\n",
      "Epoch 16/20\n",
      "1375/1375 [==============================] - 1s 1ms/step - loss: 0.2254 - accuracy: 0.9229 - val_loss: 0.2396 - val_accuracy: 0.9190\n",
      "Epoch 17/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2224 - accuracy: 0.9228 - val_loss: 0.2421 - val_accuracy: 0.9200\n",
      "Epoch 18/20\n",
      "1375/1375 [==============================] - 1s 1ms/step - loss: 0.2204 - accuracy: 0.9237 - val_loss: 0.2399 - val_accuracy: 0.9168\n",
      "Epoch 19/20\n",
      "1375/1375 [==============================] - 1s 1ms/step - loss: 0.2182 - accuracy: 0.9250 - val_loss: 0.2368 - val_accuracy: 0.9190\n",
      "Epoch 20/20\n",
      "1375/1375 [==============================] - 1s 1ms/step - loss: 0.2152 - accuracy: 0.9262 - val_loss: 0.2368 - val_accuracy: 0.9190\n"
     ]
    }
   ],
   "source": [
    "history = model_A.fit(X_train_A, y_train_A, epochs=20,\n",
    "                      validation_data=(X_valid_A, y_valid_A))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "model_A.save(\"my_model_A.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "model_B = Sequential()\n",
    "model_B.add(Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_B.add(Dense(n_hidden, activation=\"selu\"))\n",
    "model_B.add(Dense(1, activation=\"sigmoid\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "model_B.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=gradient_descent_v2.SGD(learning_rate=1e-3),\n",
    "                metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.7091 - accuracy: 0.5450 - val_loss: 0.5881 - val_accuracy: 0.6815\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.5596 - accuracy: 0.7500 - val_loss: 0.4990 - val_accuracy: 0.7718\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4744 - accuracy: 0.8250 - val_loss: 0.4309 - val_accuracy: 0.8448\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4096 - accuracy: 0.8850 - val_loss: 0.3750 - val_accuracy: 0.8966\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.3553 - accuracy: 0.9250 - val_loss: 0.3331 - val_accuracy: 0.9138\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3145 - accuracy: 0.9450 - val_loss: 0.2993 - val_accuracy: 0.9361\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2825 - accuracy: 0.9600 - val_loss: 0.2729 - val_accuracy: 0.9473\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2562 - accuracy: 0.9650 - val_loss: 0.2514 - val_accuracy: 0.9544\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2347 - accuracy: 0.9700 - val_loss: 0.2323 - val_accuracy: 0.9584\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2165 - accuracy: 0.9700 - val_loss: 0.2168 - val_accuracy: 0.9665\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2008 - accuracy: 0.9750 - val_loss: 0.2036 - val_accuracy: 0.9726\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1877 - accuracy: 0.9850 - val_loss: 0.1916 - val_accuracy: 0.9736\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1757 - accuracy: 0.9850 - val_loss: 0.1809 - val_accuracy: 0.9767\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1652 - accuracy: 0.9850 - val_loss: 0.1724 - val_accuracy: 0.9767\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1567 - accuracy: 0.9850 - val_loss: 0.1643 - val_accuracy: 0.9777\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.1487 - accuracy: 0.9900 - val_loss: 0.1572 - val_accuracy: 0.9787\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.1419 - accuracy: 0.9900 - val_loss: 0.1509 - val_accuracy: 0.9787\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.1355 - accuracy: 0.9900 - val_loss: 0.1451 - val_accuracy: 0.9787\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1298 - accuracy: 0.9900 - val_loss: 0.1397 - val_accuracy: 0.9787\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1245 - accuracy: 0.9900 - val_loss: 0.1347 - val_accuracy: 0.9797\n"
     ]
    }
   ],
   "source": [
    "history = model_B.fit(X_train_B, y_train_B, epochs=20,\n",
    "                      validation_data=(X_valid_B, y_valid_B))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 275,801\n",
      "Trainable params: 275,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_B.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model_A: Sequential = load_model(\"my_model_A.h5\")\n",
    "model_B_on_A = Sequential(model_A.layers[:-1])  # no output layer\n",
    "model_B_on_A.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# Note that model_B_on_A and model_A share layers now, so when we train one, it will update both models. If we want to avoid that, we need to build model_B_on_A on top of a clone of model_A:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "from keras.models import clone_model\n",
    "\n",
    "model_A_clone = clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())\n",
    "model_B_on_A = Sequential(model_A_clone.layers[:-1])\n",
    "model_B_on_A.add(Dense(1, activation=\"sigmoid\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:  # Freezing all hidden layers\n",
    "    layer.trainable = False\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.1134 - accuracy: 0.9750 - val_loss: 0.1219 - val_accuracy: 0.9736\n",
      "Epoch 2/4\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0988 - accuracy: 0.9850 - val_loss: 0.1100 - val_accuracy: 0.9757\n",
      "Epoch 3/4\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0881 - accuracy: 0.9850 - val_loss: 0.1006 - val_accuracy: 0.9807\n",
      "Epoch 4/4\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0797 - accuracy: 0.9850 - val_loss: 0.0919 - val_accuracy: 0.9838\n"
     ]
    }
   ],
   "source": [
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4, validation_data=(X_valid_B, y_valid_B))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0714 - accuracy: 0.9850 - val_loss: 0.0839 - val_accuracy: 0.9888\n",
      "Epoch 2/16\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0647 - accuracy: 0.9900 - val_loss: 0.0778 - val_accuracy: 0.9899\n",
      "Epoch 3/16\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0594 - accuracy: 0.9950 - val_loss: 0.0734 - val_accuracy: 0.9899\n",
      "Epoch 4/16\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0557 - accuracy: 0.9950 - val_loss: 0.0695 - val_accuracy: 0.9899\n",
      "Epoch 5/16\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0522 - accuracy: 0.9950 - val_loss: 0.0658 - val_accuracy: 0.9899\n",
      "Epoch 6/16\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0490 - accuracy: 0.9950 - val_loss: 0.0630 - val_accuracy: 0.9909\n",
      "Epoch 7/16\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0465 - accuracy: 0.9950 - val_loss: 0.0606 - val_accuracy: 0.9919\n",
      "Epoch 8/16\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0442 - accuracy: 0.9950 - val_loss: 0.0584 - val_accuracy: 0.9919\n",
      "Epoch 9/16\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0422 - accuracy: 0.9950 - val_loss: 0.0565 - val_accuracy: 0.9919\n",
      "Epoch 10/16\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0404 - accuracy: 0.9950 - val_loss: 0.0547 - val_accuracy: 0.9919\n",
      "Epoch 11/16\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0388 - accuracy: 0.9950 - val_loss: 0.0531 - val_accuracy: 0.9929\n",
      "Epoch 12/16\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0371 - accuracy: 0.9950 - val_loss: 0.0517 - val_accuracy: 0.9929\n",
      "Epoch 13/16\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0358 - accuracy: 0.9950 - val_loss: 0.0505 - val_accuracy: 0.9929\n",
      "Epoch 14/16\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0345 - accuracy: 0.9950 - val_loss: 0.0493 - val_accuracy: 0.9929\n",
      "Epoch 15/16\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0332 - accuracy: 0.9950 - val_loss: 0.0480 - val_accuracy: 0.9929\n",
      "Epoch 16/16\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0320 - accuracy: 0.9950 - val_loss: 0.0468 - val_accuracy: 0.9929\n"
     ]
    }
   ],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=gradient_descent_v2.SGD(learning_rate=1e-3),\n",
    "                     metrics=[\"accuracy\"])\n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16,\n",
    "                           validation_data=(X_valid_B, y_valid_B))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 654us/step - loss: 0.1327 - accuracy: 0.9835\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.13267095386981964, 0.9835000038146973]"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B.evaluate(X_test_B, y_test_B)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0390 - accuracy: 0.9985\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.03900434821844101, 0.9984999895095825]"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B_on_A.evaluate(X_test_B, y_test_B)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Momentum Optimization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "_ = gradient_descent_v2.SGD(momentum=0.9)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Nesterov Accelerated Gradient"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "_ = gradient_descent_v2.SGD(momentum=0.9, nesterov=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### AdaGrad"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "from keras.optimizers import adagrad_v2\n",
    "\n",
    "_ = adagrad_v2.Adagrad()  # not recommended for nn, since it can stop to early"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### RMSProp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "from keras.optimizers import rmsprop_v2\n",
    "\n",
    "_ = rmsprop_v2.RMSprop(learning_rate=0.001, rho=0.9)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Adam and Nadam\n",
    "nadam is Adam + Nesterov Trick"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "from keras.optimizers import adam_v2\n",
    "\n",
    "_ = adam_v2.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Learning Rate Schedulers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Power Scheduling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "_ = gradient_descent_v2.SGD(learning_rate=0.01, decay=1e-4)  # decay adds power scheduling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Exponential scheduling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# with hardcoded values\n",
    "def exponential_decay_fn(epoch: int) -> float:\n",
    "    return 0.01 * 0.1 ** (epoch / 20)\n",
    "\n",
    "\n",
    "# with input values\n",
    "def exponential_decay(lr0: float, s: int):\n",
    "    def exponential_decay_fn(epoch: int) -> float:\n",
    "        return lr0 * 0.1 ** (epoch / s)\n",
    "\n",
    "    return exponential_decay_fn\n",
    "\n",
    "\n",
    "exponential_decay_fn = exponential_decay(lr0=0.01, s=20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape=[28, 28]),\n",
    "    Dense(300, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    Dense(100, activation=\"selu\", kernel_initializer=\"lecun_normal\"),\n",
    "    Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\n",
    "n_epochs = 25"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.8394 - accuracy: 0.7605 - val_loss: 0.8355 - val_accuracy: 0.7960 - lr: 0.0100\n",
      "Epoch 2/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.6491 - accuracy: 0.8035 - val_loss: 0.6450 - val_accuracy: 0.8380 - lr: 0.0089\n",
      "Epoch 3/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.6314 - accuracy: 0.8072 - val_loss: 0.9756 - val_accuracy: 0.7168 - lr: 0.0079\n",
      "Epoch 4/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.5329 - accuracy: 0.8321 - val_loss: 0.6138 - val_accuracy: 0.8156 - lr: 0.0071\n",
      "Epoch 5/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4874 - accuracy: 0.8453 - val_loss: 0.6354 - val_accuracy: 0.7814 - lr: 0.0063\n",
      "Epoch 6/25\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.4329 - accuracy: 0.8615 - val_loss: 0.5133 - val_accuracy: 0.8442 - lr: 0.0056\n",
      "Epoch 7/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.4095 - accuracy: 0.8682 - val_loss: 0.4771 - val_accuracy: 0.8552 - lr: 0.0050\n",
      "Epoch 8/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3812 - accuracy: 0.8755 - val_loss: 0.4524 - val_accuracy: 0.8614 - lr: 0.0045\n",
      "Epoch 9/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.3552 - accuracy: 0.8829 - val_loss: 0.4589 - val_accuracy: 0.8676 - lr: 0.0040\n",
      "Epoch 10/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3215 - accuracy: 0.8935 - val_loss: 0.4586 - val_accuracy: 0.8694 - lr: 0.0035\n",
      "Epoch 11/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3044 - accuracy: 0.8979 - val_loss: 0.5154 - val_accuracy: 0.8696 - lr: 0.0032\n",
      "Epoch 12/25\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.2848 - accuracy: 0.9049 - val_loss: 0.4525 - val_accuracy: 0.8672 - lr: 0.0028\n",
      "Epoch 13/25\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.2641 - accuracy: 0.9100 - val_loss: 0.4312 - val_accuracy: 0.8836 - lr: 0.0025\n",
      "Epoch 14/25\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.2457 - accuracy: 0.9165 - val_loss: 0.4474 - val_accuracy: 0.8818 - lr: 0.0022\n",
      "Epoch 15/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2282 - accuracy: 0.9213 - val_loss: 0.4727 - val_accuracy: 0.8830 - lr: 0.0020\n",
      "Epoch 16/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.2141 - accuracy: 0.9253 - val_loss: 0.4647 - val_accuracy: 0.8836 - lr: 0.0018\n",
      "Epoch 17/25\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2014 - accuracy: 0.9299 - val_loss: 0.5122 - val_accuracy: 0.8768 - lr: 0.0016\n",
      "Epoch 18/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.1854 - accuracy: 0.9370 - val_loss: 0.4984 - val_accuracy: 0.8838 - lr: 0.0014\n",
      "Epoch 19/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.1724 - accuracy: 0.9402 - val_loss: 0.5095 - val_accuracy: 0.8858 - lr: 0.0013\n",
      "Epoch 20/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.1632 - accuracy: 0.9450 - val_loss: 0.5424 - val_accuracy: 0.8884 - lr: 0.0011\n",
      "Epoch 21/25\n",
      "1719/1719 [==============================] - 3s 1ms/step - loss: 0.1543 - accuracy: 0.9482 - val_loss: 0.5028 - val_accuracy: 0.8872 - lr: 0.0010\n",
      "Epoch 22/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.1428 - accuracy: 0.9522 - val_loss: 0.5190 - val_accuracy: 0.8888 - lr: 8.9125e-04\n",
      "Epoch 23/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.1336 - accuracy: 0.9550 - val_loss: 0.5506 - val_accuracy: 0.8930 - lr: 7.9433e-04\n",
      "Epoch 24/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.1263 - accuracy: 0.9582 - val_loss: 0.6029 - val_accuracy: 0.8914 - lr: 7.0795e-04\n",
      "Epoch 25/25\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.1213 - accuracy: 0.9597 - val_loss: 0.6195 - val_accuracy: 0.8860 - lr: 6.3096e-04\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(exponential_decay_fn)\n",
    "history = model.fit(X_train_scaled, y_train, epochs=n_epochs, validation_data=(X_valid_scaled, y_valid),\n",
    "                    callbacks=[lr_scheduler])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# decay will start at the beginning of epoch 0 instead of 1. Will rely upon existing lr (e.g. existing model)\n",
    "def exponential_decay_fn(epoch: int, lr: float) -> float:\n",
    "    return lr * 0.1 ** (epoch / 20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Piecewise constant scheduling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def piecewise_constant_fn(epoch: int) -> float:\n",
    "    if epoch < 5:\n",
    "        return 0.01\n",
    "    elif epoch < 15:\n",
    "        return 0.005\n",
    "    else:\n",
    "        return 0.001"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Performance scheduling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "_ = ReduceLROnPlateau(factor=0.5, patience=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "s = 20 * len(X_train) // 32  # number of steps in 20 epochs (batch size = 32)\n",
    "learning_rate = ExponentialDecay(0.01, s, 0.1)\n",
    "optimizer = gradient_descent_v2.SGD(learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}