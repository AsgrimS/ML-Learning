{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "import keras.losses\n",
    "from keras.layers import Flatten, Dense, BatchNormalization\n",
    "from keras.models import Sequential"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape=[28, 28]),\n",
    "    BatchNormalization(),\n",
    "    Dense(300, activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dense(100, activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    Dense(10, activation=\"softmax\")\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_3 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 784)              3136      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 300)              1200      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 100)              400       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "[('batch_normalization_10/gamma:0', True),\n ('batch_normalization_10/beta:0', True),\n ('batch_normalization_10/moving_mean:0', False),\n ('batch_normalization_10/moving_variance:0', False)]"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(var.name, var.trainable) for var in model.layers[1].variables]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Gradient Clipping"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "from keras.optimizers import gradient_descent_v2\n",
    "\n",
    "optimizer = gradient_descent_v2.SGD(clipvalue=1.0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "\n",
    "\n",
    "def split_dataset(X, y):\n",
    "    y_5_or_6 = (y == 5) | (y == 6)  # sandals or shirts\n",
    "    y_A = y[~y_5_or_6]\n",
    "    y_A[y_A > 6] -= 2  # class indices 7, 8, 9 should be moved to 5, 6, 7\n",
    "    y_B = (y[y_5_or_6] == 6).astype(np.float32)  # binary classification task: is it a shirt (class 6)?\n",
    "    return ((X[~y_5_or_6], y_A),\n",
    "            (X[y_5_or_6], y_B))\n",
    "\n",
    "\n",
    "(X_train_A, y_train_A), (X_train_B, y_train_B) = split_dataset(X_train, y_train)\n",
    "(X_valid_A, y_valid_A), (X_valid_B, y_valid_B) = split_dataset(X_valid, y_valid)\n",
    "(X_test_A, y_test_A), (X_test_B, y_test_B) = split_dataset(X_test, y_test)\n",
    "X_train_B = X_train_B[:200]\n",
    "y_train_B = y_train_B[:200]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "(43986, 28, 28)"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_A.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "(200, 28, 28)"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_B.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "model_A = Sequential()\n",
    "model_A.add(Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_A.add(Dense(n_hidden, activation=\"selu\"))\n",
    "model_A.add(Dense(8, activation=\"softmax\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "model_A.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=gradient_descent_v2.SGD(learning_rate=1e-3),\n",
    "                metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " 149/1375 [==>...........................] - ETA: 1s - loss: 1.1940 - accuracy: 0.6195"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-15 16:25:29.244291: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1375/1375 [==============================] - 2s 980us/step - loss: 0.5579 - accuracy: 0.8250 - val_loss: 0.3726 - val_accuracy: 0.8762\n",
      "Epoch 2/20\n",
      "1375/1375 [==============================] - 1s 916us/step - loss: 0.3475 - accuracy: 0.8810 - val_loss: 0.3236 - val_accuracy: 0.8914\n",
      "Epoch 3/20\n",
      "1375/1375 [==============================] - 1s 979us/step - loss: 0.3137 - accuracy: 0.8916 - val_loss: 0.2979 - val_accuracy: 0.9016\n",
      "Epoch 4/20\n",
      "1375/1375 [==============================] - 1s 1ms/step - loss: 0.2952 - accuracy: 0.8989 - val_loss: 0.2844 - val_accuracy: 0.9081\n",
      "Epoch 5/20\n",
      "1375/1375 [==============================] - 1s 1ms/step - loss: 0.2821 - accuracy: 0.9032 - val_loss: 0.2773 - val_accuracy: 0.9041\n",
      "Epoch 6/20\n",
      "1375/1375 [==============================] - 1s 966us/step - loss: 0.2728 - accuracy: 0.9066 - val_loss: 0.2749 - val_accuracy: 0.9046\n",
      "Epoch 7/20\n",
      "1375/1375 [==============================] - 1s 951us/step - loss: 0.2649 - accuracy: 0.9095 - val_loss: 0.2718 - val_accuracy: 0.9081\n",
      "Epoch 8/20\n",
      "1375/1375 [==============================] - 1s 947us/step - loss: 0.2586 - accuracy: 0.9117 - val_loss: 0.2588 - val_accuracy: 0.9123\n",
      "Epoch 9/20\n",
      "1375/1375 [==============================] - 1s 921us/step - loss: 0.2534 - accuracy: 0.9133 - val_loss: 0.2556 - val_accuracy: 0.9126\n",
      "Epoch 10/20\n",
      "1375/1375 [==============================] - 1s 944us/step - loss: 0.2482 - accuracy: 0.9159 - val_loss: 0.2531 - val_accuracy: 0.9150\n",
      "Epoch 11/20\n",
      "1375/1375 [==============================] - 1s 1ms/step - loss: 0.2438 - accuracy: 0.9170 - val_loss: 0.2583 - val_accuracy: 0.9141\n",
      "Epoch 12/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2402 - accuracy: 0.9181 - val_loss: 0.2506 - val_accuracy: 0.9133\n",
      "Epoch 13/20\n",
      "1375/1375 [==============================] - 1s 1ms/step - loss: 0.2363 - accuracy: 0.9191 - val_loss: 0.2600 - val_accuracy: 0.9093\n",
      "Epoch 14/20\n",
      "1375/1375 [==============================] - 1s 1ms/step - loss: 0.2332 - accuracy: 0.9208 - val_loss: 0.2453 - val_accuracy: 0.9158\n",
      "Epoch 15/20\n",
      "1375/1375 [==============================] - 1s 1ms/step - loss: 0.2301 - accuracy: 0.9215 - val_loss: 0.2436 - val_accuracy: 0.9188\n",
      "Epoch 16/20\n",
      "1375/1375 [==============================] - 1s 1ms/step - loss: 0.2271 - accuracy: 0.9222 - val_loss: 0.2423 - val_accuracy: 0.9188\n",
      "Epoch 17/20\n",
      "1375/1375 [==============================] - 1s 1ms/step - loss: 0.2246 - accuracy: 0.9232 - val_loss: 0.2410 - val_accuracy: 0.9158\n",
      "Epoch 18/20\n",
      "1375/1375 [==============================] - 1s 1ms/step - loss: 0.2224 - accuracy: 0.9241 - val_loss: 0.2433 - val_accuracy: 0.9175\n",
      "Epoch 19/20\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2201 - accuracy: 0.9252 - val_loss: 0.2407 - val_accuracy: 0.9173\n",
      "Epoch 20/20\n",
      "1375/1375 [==============================] - 1s 1ms/step - loss: 0.2179 - accuracy: 0.9252 - val_loss: 0.2388 - val_accuracy: 0.9180\n"
     ]
    }
   ],
   "source": [
    "history = model_A.fit(X_train_A, y_train_A, epochs=20,\n",
    "                      validation_data=(X_valid_A, y_valid_A))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "model_A.save(\"my_model_A.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "model_B = Sequential()\n",
    "model_B.add(Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_B.add(Dense(n_hidden, activation=\"selu\"))\n",
    "model_B.add(Dense(1, activation=\"sigmoid\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "model_B.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer=gradient_descent_v2.SGD(learning_rate=1e-3),\n",
    "                metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6125 - accuracy: 0.7000 - val_loss: 0.5306 - val_accuracy: 0.7748\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.4405 - accuracy: 0.8300 - val_loss: 0.4127 - val_accuracy: 0.8529\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.3394 - accuracy: 0.8850 - val_loss: 0.3372 - val_accuracy: 0.8986\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.2715 - accuracy: 0.9400 - val_loss: 0.2873 - val_accuracy: 0.9209\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2275 - accuracy: 0.9700 - val_loss: 0.2517 - val_accuracy: 0.9320\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1950 - accuracy: 0.9700 - val_loss: 0.2243 - val_accuracy: 0.9402\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1701 - accuracy: 0.9850 - val_loss: 0.2014 - val_accuracy: 0.9584\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1495 - accuracy: 0.9950 - val_loss: 0.1846 - val_accuracy: 0.9615\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1338 - accuracy: 0.9950 - val_loss: 0.1704 - val_accuracy: 0.9615\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1206 - accuracy: 0.9950 - val_loss: 0.1593 - val_accuracy: 0.9635\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1101 - accuracy: 0.9950 - val_loss: 0.1489 - val_accuracy: 0.9675\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1009 - accuracy: 0.9950 - val_loss: 0.1406 - val_accuracy: 0.9686\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0933 - accuracy: 0.9950 - val_loss: 0.1336 - val_accuracy: 0.9696\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0864 - accuracy: 0.9950 - val_loss: 0.1275 - val_accuracy: 0.9706\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0808 - accuracy: 0.9950 - val_loss: 0.1217 - val_accuracy: 0.9696\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0757 - accuracy: 0.9950 - val_loss: 0.1170 - val_accuracy: 0.9706\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0712 - accuracy: 0.9950 - val_loss: 0.1124 - val_accuracy: 0.9726\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0673 - accuracy: 0.9950 - val_loss: 0.1087 - val_accuracy: 0.9736\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0639 - accuracy: 0.9950 - val_loss: 0.1054 - val_accuracy: 0.9746\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0607 - accuracy: 0.9950 - val_loss: 0.1019 - val_accuracy: 0.9746\n"
     ]
    }
   ],
   "source": [
    "history = model_B.fit(X_train_B, y_train_B, epochs=20,\n",
    "                      validation_data=(X_valid_B, y_valid_B))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_5 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 275,801\n",
      "Trainable params: 275,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_B.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model_A: Sequential = load_model(\"my_model_A.h5\")\n",
    "model_B_on_A = Sequential(model_A.layers[:-1])  # no output layer\n",
    "model_B_on_A.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# Note that model_B_on_A and model_A share layers now, so when we train one, it will update both models. If we want to avoid that, we need to build model_B_on_A on top of a clone of model_A:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "from keras.models import clone_model\n",
    "\n",
    "model_A_clone = clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())\n",
    "model_B_on_A = Sequential(model_A_clone.layers[:-1])\n",
    "model_B_on_A.add(Dense(1, activation=\"sigmoid\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:  # Freezing all hidden layers\n",
    "    layer.trainable = False\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.0458 - accuracy: 0.9950 - val_loss: 0.0561 - val_accuracy: 0.9939\n",
      "Epoch 2/4\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0434 - accuracy: 0.9950 - val_loss: 0.0538 - val_accuracy: 0.9939\n",
      "Epoch 3/4\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0414 - accuracy: 0.9950 - val_loss: 0.0518 - val_accuracy: 0.9939\n",
      "Epoch 4/4\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0395 - accuracy: 0.9950 - val_loss: 0.0499 - val_accuracy: 0.9939\n"
     ]
    }
   ],
   "source": [
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=4, validation_data=(X_valid_B, y_valid_B))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0381 - accuracy: 0.9950 - val_loss: 0.0489 - val_accuracy: 0.9939\n",
      "Epoch 2/16\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0370 - accuracy: 0.9950 - val_loss: 0.0480 - val_accuracy: 0.9939\n",
      "Epoch 3/16\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0359 - accuracy: 0.9950 - val_loss: 0.0471 - val_accuracy: 0.9939\n",
      "Epoch 4/16\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0350 - accuracy: 0.9950 - val_loss: 0.0463 - val_accuracy: 0.9949\n",
      "Epoch 5/16\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0338 - accuracy: 0.9950 - val_loss: 0.0455 - val_accuracy: 0.9949\n",
      "Epoch 6/16\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0330 - accuracy: 0.9950 - val_loss: 0.0448 - val_accuracy: 0.9949\n",
      "Epoch 7/16\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0322 - accuracy: 0.9950 - val_loss: 0.0441 - val_accuracy: 0.9949\n",
      "Epoch 8/16\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0314 - accuracy: 0.9950 - val_loss: 0.0434 - val_accuracy: 0.9949\n",
      "Epoch 9/16\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0308 - accuracy: 0.9950 - val_loss: 0.0427 - val_accuracy: 0.9949\n",
      "Epoch 10/16\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.0421 - val_accuracy: 0.9949\n",
      "Epoch 11/16\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0293 - accuracy: 0.9950 - val_loss: 0.0416 - val_accuracy: 0.9949\n",
      "Epoch 12/16\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0286 - accuracy: 0.9950 - val_loss: 0.0409 - val_accuracy: 0.9949\n",
      "Epoch 13/16\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0279 - accuracy: 0.9950 - val_loss: 0.0404 - val_accuracy: 0.9949\n",
      "Epoch 14/16\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0274 - accuracy: 0.9950 - val_loss: 0.0399 - val_accuracy: 0.9949\n",
      "Epoch 15/16\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0268 - accuracy: 0.9950 - val_loss: 0.0394 - val_accuracy: 0.9949\n",
      "Epoch 16/16\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0263 - accuracy: 0.9950 - val_loss: 0.0389 - val_accuracy: 0.9949\n"
     ]
    }
   ],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer=gradient_descent_v2.SGD(learning_rate=1e-3),\n",
    "                     metrics=[\"accuracy\"])\n",
    "history = model_B_on_A.fit(X_train_B, y_train_B, epochs=16,\n",
    "                           validation_data=(X_valid_B, y_valid_B))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0971 - accuracy: 0.9815\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.09714802354574203, 0.9815000295639038]"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B.evaluate(X_test_B, y_test_B)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0297 - accuracy: 0.9990\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.02974965237081051, 0.9990000128746033]"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B_on_A.evaluate(X_test_B, y_test_B)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Momentum Optimization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "_ = gradient_descent_v2.SGD(momentum=0.9)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Nesterov Accelerated Gradient"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "_ = gradient_descent_v2.SGD(momentum=0.9, nesterov=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### AdaGrad"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "from keras.optimizers import adagrad_v2\n",
    "\n",
    "_ = adagrad_v2.Adagrad()  # not recommended for nn, since it can stop to early"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### RMSProp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "from keras.optimizers import rmsprop_v2\n",
    "\n",
    "_ = rmsprop_v2.RMSprop(learning_rate=0.001, rho=0.9)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Adam and Nadam\n",
    "nadam is Adam + Nesterov Trick"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.optimizers import adam_v2\n",
    "\n",
    "_ = adam_v2.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}